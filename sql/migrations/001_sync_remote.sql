-- Migration: sync_remote
-- Generated by: p8 db diff --generate
-- Date: 2026-02-23 15:40:51 UTC
-- Direction: local â†’ remote (additive)
--
-- Review before applying!
--   p8 db apply sql/migrations/001_sync_remote.sql --remote-url <REMOTE_URL>
--

ALTER TABLE moments ADD COLUMN IF NOT EXISTS rating int2;

ALTER TABLE resources ADD COLUMN IF NOT EXISTS rating int2;

-- Changed function: claim_tasks(p_tier character varying, p_worker_id character varying, p_batch_size integer)
CREATE OR REPLACE FUNCTION public.claim_tasks(p_tier character varying, p_worker_id character varying, p_batch_size integer DEFAULT 1)
 RETURNS SETOF task_queue
 LANGUAGE plpgsql
AS $function$
BEGIN
    RETURN QUERY
    WITH claimed AS (
        UPDATE task_queue
        SET status = 'processing',
            claimed_at = CURRENT_TIMESTAMP,
            claimed_by = p_worker_id,
            started_at = CURRENT_TIMESTAMP
        WHERE id IN (
            SELECT id FROM task_queue
            WHERE status = 'pending'
              AND tier = p_tier
              AND scheduled_at <= CURRENT_TIMESTAMP
            ORDER BY priority DESC, scheduled_at ASC
            LIMIT p_batch_size
            FOR UPDATE SKIP LOCKED
        )
        RETURNING *
    )
    SELECT * FROM claimed;

    -- Log claimed events
    INSERT INTO task_events (task_id, task_type, user_id, event, worker_id)
    SELECT id, task_type, user_id, 'claimed', p_worker_id
    FROM task_queue
    WHERE claimed_by = p_worker_id AND status = 'processing'
      AND claimed_at >= CURRENT_TIMESTAMP - INTERVAL '5 seconds';
END;
$function$;

-- Changed function: enqueue_file_task(p_file_id uuid, p_user_id uuid, p_tenant_id character varying)
CREATE OR REPLACE FUNCTION public.enqueue_file_task(p_file_id uuid, p_user_id uuid DEFAULT NULL::uuid, p_tenant_id character varying DEFAULT NULL::character varying)
 RETURNS uuid
 LANGUAGE plpgsql
AS $function$
DECLARE
    v_size_bytes BIGINT;
    v_tier VARCHAR;
    v_task_id UUID;
    v_uri TEXT;
    v_name TEXT;
    v_mime TEXT;
BEGIN
    SELECT size_bytes, uri, name, mime_type
    INTO v_size_bytes, v_uri, v_name, v_mime
    FROM files WHERE id = p_file_id;

    IF NOT FOUND THEN
        RAISE EXCEPTION 'File % not found', p_file_id;
    END IF;

    -- Auto-assign tier by file size
    IF COALESCE(v_size_bytes, 0) < 1048576 THEN         -- <1MB
        v_tier := 'small';
    ELSIF v_size_bytes < 52428800 THEN                    -- <50MB
        v_tier := 'medium';
    ELSE                                                   -- >=50MB
        v_tier := 'large';
    END IF;

    INSERT INTO task_queue (task_type, tier, user_id, tenant_id, payload, priority)
    VALUES (
        'file_processing',
        v_tier,
        p_user_id,
        p_tenant_id,
        jsonb_build_object(
            'file_id', p_file_id,
            'uri', v_uri,
            'name', v_name,
            'mime_type', v_mime,
            'size_bytes', v_size_bytes
        ),
        CASE WHEN COALESCE(v_size_bytes, 0) < 1048576 THEN 10 ELSE 0 END
    )
    RETURNING id INTO v_task_id;

    RETURN v_task_id;
END;
$function$;

-- Changed function: enqueue_news_tasks()
CREATE OR REPLACE FUNCTION public.enqueue_news_tasks()
 RETURNS integer
 LANGUAGE plpgsql
AS $function$
DECLARE
    v_count INT := 0;
    v_user RECORD;
BEGIN
    FOR v_user IN
        SELECT COALESCE(u.user_id, u.id) AS effective_uid, u.tenant_id
        FROM users u
        WHERE u.deleted_at IS NULL
          AND u.metadata IS NOT NULL
          AND (
              u.metadata->>'interests' IS NOT NULL
              OR u.metadata->>'categories' IS NOT NULL
          )
          -- Skip users who already have a pending/processing/completed news task today
          AND NOT EXISTS (
              SELECT 1 FROM task_queue tq
              WHERE tq.task_type = 'news'
                AND tq.user_id = COALESCE(u.user_id, u.id)
                AND tq.created_at >= date_trunc('day', CURRENT_TIMESTAMP)
                AND tq.status IN ('pending', 'processing', 'completed')
          )
    LOOP
        INSERT INTO task_queue (task_type, tier, user_id, tenant_id, payload)
        VALUES (
            'news',
            'small',
            v_user.effective_uid,
            v_user.tenant_id,
            jsonb_build_object('trigger', 'scheduled', 'enqueued_at', CURRENT_TIMESTAMP)
        );
        v_count := v_count + 1;
    END LOOP;

    RETURN v_count;
END;
$function$;

-- Changed function: fail_task(p_task_id uuid, p_error text)
CREATE OR REPLACE FUNCTION public.fail_task(p_task_id uuid, p_error text)
 RETURNS void
 LANGUAGE plpgsql
AS $function$
DECLARE
    v_retry_count INT;
    v_max_retries INT;
    v_backoff INTERVAL;
BEGIN
    SELECT retry_count, max_retries INTO v_retry_count, v_max_retries
    FROM task_queue WHERE id = p_task_id;

    IF v_retry_count < v_max_retries THEN
        -- Exponential backoff: 30s * 4^retry_count (30s, 2m, 8m, 32m, ...)
        v_backoff := (30 * power(4, v_retry_count)) * INTERVAL '1 second';
        UPDATE task_queue
        SET status = 'pending',
            error = p_error,
            retry_count = retry_count + 1,
            scheduled_at = CURRENT_TIMESTAMP + v_backoff,
            claimed_at = NULL,
            claimed_by = NULL,
            started_at = NULL
        WHERE id = p_task_id;

        PERFORM emit_task_event(p_task_id, 'retrying', NULL, p_error,
            jsonb_build_object('retry', v_retry_count + 1, 'max_retries', v_max_retries,
                               'next_attempt', CURRENT_TIMESTAMP + v_backoff));
    ELSE
        UPDATE task_queue
        SET status = 'failed',
            error = p_error,
            completed_at = CURRENT_TIMESTAMP
        WHERE id = p_task_id;

        PERFORM emit_task_event(p_task_id, 'failed', NULL, p_error,
            jsonb_build_object('retry', v_retry_count, 'max_retries', v_max_retries));
    END IF;
END;
$function$;

-- Changed function: recover_stale_tasks(p_timeout_minutes integer)
CREATE OR REPLACE FUNCTION public.recover_stale_tasks(p_timeout_minutes integer DEFAULT 15)
 RETURNS integer
 LANGUAGE plpgsql
AS $function$
DECLARE
    v_count INT;
BEGIN
    -- Log recovered events before updating
    INSERT INTO task_events (task_id, task_type, user_id, event, worker_id, error, detail)
    SELECT id, task_type, user_id, 'recovered', claimed_by,
           'processing timeout after ' || p_timeout_minutes || ' minutes',
           jsonb_build_object('retry', retry_count + 1, 'claimed_at', claimed_at)
    FROM task_queue
    WHERE status = 'processing'
      AND claimed_at < CURRENT_TIMESTAMP - (p_timeout_minutes || ' minutes')::interval
      AND retry_count < max_retries;

    UPDATE task_queue
    SET status = 'pending',
        error = 'recovered: processing timeout after ' || p_timeout_minutes || ' minutes',
        retry_count = retry_count + 1,
        scheduled_at = CURRENT_TIMESTAMP,
        claimed_at = NULL,
        claimed_by = NULL,
        started_at = NULL
    WHERE status = 'processing'
      AND claimed_at < CURRENT_TIMESTAMP - (p_timeout_minutes || ' minutes')::interval
      AND retry_count < max_retries;

    GET DIAGNOSTICS v_count = ROW_COUNT;

    -- Log permanently failed events before updating
    INSERT INTO task_events (task_id, task_type, user_id, event, worker_id, error, detail)
    SELECT id, task_type, user_id, 'failed', claimed_by,
           'exceeded max retries after processing timeout',
           jsonb_build_object('retry', retry_count, 'max_retries', max_retries, 'claimed_at', claimed_at)
    FROM task_queue
    WHERE status = 'processing'
      AND claimed_at < CURRENT_TIMESTAMP - (p_timeout_minutes || ' minutes')::interval
      AND retry_count >= max_retries;

    -- Mark permanently failed if max retries exceeded
    UPDATE task_queue
    SET status = 'failed',
        error = 'recovered: exceeded max retries after processing timeout',
        completed_at = CURRENT_TIMESTAMP
    WHERE status = 'processing'
      AND claimed_at < CURRENT_TIMESTAMP - (p_timeout_minutes || ' minutes')::interval
      AND retry_count >= max_retries;

    RETURN v_count;
END;
$function$;
